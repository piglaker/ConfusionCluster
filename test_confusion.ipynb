{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_model_name_path=\"hfl/chinese-roberta-wwm-ext\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_model_name_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"投陋的小明的成基差劫极了。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(\"/remote-home/xtzhang/CTC/CTC2021/SE_tmp_back/tmp/sighan/bert_MaskedLM_base_raw.epoch10.bs128\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tokenizer(x)\n",
    "import torch\n",
    "source = { k:torch.tensor([v]) for k,v in tmp.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2832, 7358, 4638, 2207, 3209, 4638, 2768, 1825, 2345, 1223, 3353, 749, 511, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.softmax(model(**source).logits, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15, 21128])\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4995, 0.2312, 0.1092, 0.0425, 0.0314, 0.0203, 0.0073, 0.0071, 0.0061,\n",
      "        0.0059], grad_fn=<SelectBackward0>)\n",
      "tensor([5110, 5042,  682, 2577, 1928, 1936, 1159, 3193, 2405, 6577])\n",
      "tensor(0.4995, grad_fn=<SelectBackward0>) 粗\n",
      "tensor(0.2312, grad_fn=<SelectBackward0>) 简\n",
      "tensor(0.1092, grad_fn=<SelectBackward0>) 丑\n",
      "tensor(0.0425, grad_fn=<SelectBackward0>) 怀\n",
      "tensor(0.0314, grad_fn=<SelectBackward0>) 头\n",
      "tensor(0.0203, grad_fn=<SelectBackward0>) 奇\n",
      "tensor(0.0073, grad_fn=<SelectBackward0>) 初\n",
      "tensor(0.0071, grad_fn=<SelectBackward0>) 早\n",
      "tensor(0.0061, grad_fn=<SelectBackward0>) 幼\n",
      "tensor(0.0059, grad_fn=<SelectBackward0>) 贫\n"
     ]
    }
   ],
   "source": [
    "#c = torch.argmax(q, 2)\n",
    "p = torch.topk(preds, 10)[0][0][1]\n",
    "c = torch.topk(preds, 10)[-1][0][1]\n",
    "\n",
    "print(p)\n",
    "print(c)\n",
    "\n",
    "for o, i in enumerate(c):\n",
    "    print(p[o], tokenizer.decode(i.numpy().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] 粗 陋 的 小 明 的 成 绩 差 劲 极 了 。 [SEP]']\n"
     ]
    }
   ],
   "source": [
    "pred = torch.argmax(preds, dim=2)\n",
    "print(tokenizer.batch_decode(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS] 投 陋 的 小 明 的 成 基 差 劫 极 了 。 [SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(source[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 5110, 7358, 4638, 2207, 3209, 4638, 2768, 5327, 2345, 1226, 3353,\n",
      "          749,  511,  102]])\n",
      "tensor([[ 101, 2832, 7358, 4638, 2207, 3209, 4638, 2768, 1825, 2345, 1223, 3353,\n",
      "          749,  511,  102]])\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(source[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [Reader] [Building Confusion]\n",
      "[INFO] [Reader] [Building Graph]\n",
      "[INFO] [Reader] [Init Vocab]\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/confusion.txt\"\n",
    "\n",
    "import reader\n",
    "confusion_reader = reader.ConfusionSetReader()\n",
    "\n",
    "confusion_reader.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['又', '透', '壹', '扭', '技', '丑', '援', '役', '没', '偷', '窦', '设', '头', '昱', '股']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_reader.graph[\"投\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5110, 5042,  682, 2577, 1928])\n"
     ]
    }
   ],
   "source": [
    "z = torch.topk(preds, 5)[1][0][1]\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1348, 6851, 1902, 2814, 2825, 682, 3001, 2514, 3766, 982, 4977, 6392, 1928, 3222, 5500]\n"
     ]
    }
   ],
   "source": [
    "def get_sim(i):\n",
    "    confusion = confusion_reader.graph[tokenizer.decode(i)]\n",
    "    return [ tokenizer.convert_tokens_to_ids(j) for j in confusion]\n",
    "\n",
    "print(get_sim(2832))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(101)\n",
      "tensor([ 101, 2832, 7358, 4638, 2207, 3209, 4638, 2768, 1825, 2345, 1223, 3353,\n",
      "         749,  511,  102])\n"
     ]
    }
   ],
   "source": [
    "print(pred[0][0])\n",
    "print(source[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"得\")#4638, 1765, 2533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 丑 陋 的 小 明 的 成 绩 差 劲 极 了 。 [SEP]\n"
     ]
    }
   ],
   "source": [
    "p = torch.topk(preds, 5)[0][0]\n",
    "c = torch.topk(preds, 5)[-1][0]\n",
    "\n",
    "new_preds = []\n",
    "\n",
    "for i in range(len(pred[0])):\n",
    "    if pred[0][i] != source[\"input_ids\"][0][i]:\n",
    "        confusion = get_sim(source[\"input_ids\"][0][i])\n",
    "        for j in range(len(c[i])):\n",
    "            if c[i][j] in confusion:\n",
    "                new_preds.append(c[i][j])\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        new_preds.append(pred[0][i])\n",
    "\n",
    "print(tokenizer.decode(new_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('115')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90bb92497ec70e1ac59ff7125de72f80cb7d571a10b970670d76fc816afd7bfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
